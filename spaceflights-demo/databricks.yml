# yaml-language-server: $schema=bundle_config_schema.json

bundle:
  name: spaceflights

resources:
  jobs:
    spaceflights-job:
      name: spaceflights-job
      tasks:
        - task_key: spaceflights-task
          # existing_cluster_id: 0819-144304-z2g7w16n      
          notebook_task:
            notebook_path: ./run.py
          # spark_python_task:
          #   python_file: ./run_cli.py

targets:
  dev:
    mode: development
    default: true
    workspace:
      host: https://e2-demo-field-eng.cloud.databricks.com/


  # # The 'prod' target, used for production deployment.
  # prod:
  #   # We use 'mode: production' to indicate this is a production deployment.
  #   # Doing so enables strict verification of the settings below.
  #   mode: production
  #   workspace:
  #     host: https://e2-demo-field-eng.cloud.databricks.com/
  #     # We always use /Users/user@company.com for all resources to make sure we only have a single copy.
  #     # If this path results in an error, please make sure you have a recent version of the CLI installed.
  #     root_path: /Users/user@company.com/.bundle/${bundle.name}/${bundle.target}
  #   run_as:
  #     # This runs as user@company.com in production. We could also use a service principal here,
  #     # see https://docs.databricks.com/dev-tools/bundles/permissions.html.
  #     user_name: user@company.com
    
